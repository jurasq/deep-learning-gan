{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                         1.8.0      \n",
      "/home/nemezis/.local/share/virtualenvs/deep-learning-gan-1-A8PU3N/bin/python2.7\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tensorflow\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper definitions:\n",
    "Enhancer paper = \"Enhancer Identification from DNA sequence using Transfer and Adversarial Deep Learning\"  \n",
    "triple GAN = \"Triple Generative Adversarial Nets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_fn(sample):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        sample: (string) String of DNA data of length n, example: ACTGTA...\n",
    "    Outputs:\n",
    "        A numpy array of size n x 4 where A in the DNA sequence has been replace with [1 0 0 0], C with [0 1 0 0],\n",
    "        G with [0 0 1 0] and T with [0 0 0 1].\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    mapping = tf.constant([\"A\", \"C\", \"G\", \"T\"])\n",
    "    embeddings = tf.constant([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "    sample_split = tf.string_split([sample], '')\n",
    "    lookup_table = tf.contrib.lookup.index_table_from_tensor(mapping = mapping, num_oov_buckets = 0)\n",
    "    lookup_table.init.run()\n",
    "    sample_indices = lookup_table.lookup(sample_split.values)\n",
    "    encoded = tf.nn.embedding_lookup(embeddings, sample_indices)\n",
    "\n",
    "    return encoded\n",
    "\n",
    "    \n",
    "def input_fn(data_file_names):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        data_file_names: (string/string array) List of files to be loaded. * can be used as a wildcard in file names.\n",
    "    Outputs:\n",
    "        Tensor flow dataset containing the data matrices from data_file_names\n",
    "    \"\"\"\n",
    "    files = tf.data.Dataset.list_files(data_file_names)\n",
    "#     dataset = files.interleave(lambda x: tf.data.TextLineDataset(x).map(data_process_fn), cycle_length = 1)\n",
    "    dataset = files.interleave(lambda x: tf.data.TextLineDataset(x), cycle_length = 1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of data loading - human positive samples\n",
    "\n",
    "with  tf.Session() as sess:\n",
    "    \n",
    "    input_data_example = input_fn(\"Data/Human/positive_samples\")\n",
    "    iter = input_data_example.make_one_shot_iterator()\n",
    "    val = iter.get_next()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 1, 20]\n",
      "[1, 2, 2, 1]\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kernel_shape=[4,9]\n",
    "input_channels = 1\n",
    "num_kernels = 20\n",
    "\n",
    "weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "print(weights_shape)\n",
    "print([1] + [2, 2] + [1])\n",
    "print(int(500/8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(name_scope, input_tensor, num_kernels, kernel_shape, stride=1, padding=\"VALID\", relu=True, lrelu=False,batch_normalize=False, batch_normalize_training=True, name_suffix=None, batch_norm=False):\n",
    "    \"\"\"\n",
    "    Return a convolution layer, possibly with a ReLU at the end.\n",
    "    :param name_scope:   where the variables live\n",
    "    :param input_tensor: of shape [batch, in_height, in_width, in_channels], e.g. [15 500 4 1]\n",
    "    :param num_kernels:  number of kernels to use for this conv. layer\n",
    "    :param kernel_shape: the shape of the kernel to use, [height, width]\n",
    "    \"\"\"\n",
    "    name_suffix = name_suffix if name_suffix else \"\"\n",
    "    \n",
    "    #E.g. batch_size x 500x4x1 for the first input\n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1]\n",
    "    \n",
    "    #not really sure why I'm using the name_scope, I think it's mostly for presentation purposes\n",
    "    with tf.name_scope(name_scope):\n",
    "        \n",
    "        weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "        init_vals_weights = tf.truncated_normal(weights_shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        filter_weights = tf.Variable(init_vals_weights, name='weights'+name_suffix)\n",
    "    \n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases'+name_suffix)\n",
    "        \n",
    "        #Define a convolutional layer\n",
    "        layer = tf.nn.conv2d(input_tensor, filter_weights, strides=[1, stride, stride, 1], padding=padding) + biases\n",
    "        \n",
    "        #Add batch normalisation if specified\n",
    "        #TODO: is_training always True?\n",
    "        if batch_norm:\n",
    "            layer = tf.contrib.layers.batch_norm(inputs = layer, center=True, scale=True, is_training=True)\n",
    "            \n",
    "        #Add (leaky) ReLU if specified\n",
    "        if relu and lrelu:\n",
    "            layer = tf.nn.leaky_relu(layer, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            layer = tf.nn.relu(layer, name=\"relu_\"+name_suffix)\n",
    "            \n",
    "        return layer\n",
    "\n",
    "def conv_max_forward_reverse(name_scope, input_tensor, num_kernels, kernel_shape, stride=1, padding='VALID', relu=True, lrelu=False, name_suffix=None):\n",
    "    \"\"\"\n",
    "    Returns a convolution layer\n",
    "    \"\"\"\n",
    "    name_suffix = name_suffix if name_suffix else \"\"\n",
    "    \n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1] # number of input channels\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = kernel_shape + [input_channels, num_kernels]\n",
    "        initer = tf.truncated_normal(shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        weights = tf.Variable(initer, name='weights')\n",
    "        num_kernels = weights.get_shape()[3]\n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases')\n",
    "\n",
    "        # If one component of shape is the special value -1, the size of that dimension is computed\n",
    "        #  so that the total size remains constant.\n",
    "        # In our case: -1 is inferred to be input_channels * out_channels:\n",
    "        new_weights_shape = [-1] + kernel_shape + [1]\n",
    "        w_image = tf.reshape(weights, new_weights_shape)\n",
    "        tf.summary.image(name_scope + \"_weights_im\", w_image, weights.get_shape()[3])\n",
    "        forward_conv = tf.nn.conv2d(input_tensor, weights, strides=[1, stride, stride, 1], padding=padding,name=\"forward_conv\") + biases\n",
    "        # for reverse complement: reverse in dimension 0 and 1:\n",
    "        rev_comp_weights = tf.reverse(weights, [0, 1], name=\"reverse_weights\")\n",
    "        reverse_conv = tf.nn.conv2d(input_tensor, rev_comp_weights,strides=[1, stride, stride, 1], padding=padding,name=\"reverse_conv\") + biases\n",
    "        # takes the maximum between the forward weights and the rev.-comp.-weights:\n",
    "        max_conv = tf.maximum(forward_conv, reverse_conv, name=\"conv1\")\n",
    "        if relu and lrelu:\n",
    "            return tf.nn.leaky_relu(max_conv, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            return tf.nn.relu(max_conv, name=\"relu_\"+name_suffix)\n",
    "        else:\n",
    "            return max_conv\n",
    "        \n",
    "def max_pool_layer(name_scope, input_tensor, pool_size, strides = None, padding=\"SAME\"):\n",
    "    \"\"\"\n",
    "    Return a max pool layer.\n",
    "    \"\"\"\n",
    "    if not strides:\n",
    "        strides = [1] + pool_size + [1]\n",
    "       \n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        layer = tf.nn.max_pool(input_tensor, [1] + pool_size + [1], strides=strides, padding=padding)\n",
    "        return layer\n",
    "\n",
    "\n",
    "def dropout_layer(name_scope, input_tensor, keep_prob=0.5):\n",
    "    \"\"\"\n",
    "    Return a dropout layer.\n",
    "    \"\"\"\n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        return tf.nn.droupout(input_tensor, keep_prob)\n",
    "    \n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    Returns a flat (one-dimensional) version of the input\n",
    "    \"\"\"\n",
    "    x_shape = x.get_shape().as_list()\n",
    "    return tf.reshape(x, [-1, np.product(x_shape[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classifier(dna_sequence):\n",
    "#     \"\"\"\n",
    "#     Return the same classifier, with architecture the same as they used in Enhancer paper.\n",
    "#     \"\"\"\n",
    "#     # 20 filters, each of size batch x 9x4x1\n",
    "#     # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "#     with tf.variable_scope('classifier') as scope:\n",
    "#         if (reuse):\n",
    "#             tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        \n",
    "#         l1 =  conv_max_forward_reverse(data, name_scope=\"layer1\", num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "    #TODO finish\n",
    "\n",
    "def discriminator(dna_sequence, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            \n",
    "        # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "\n",
    "        # convolutional + pooling #1\n",
    "        l1 = conv_layer(name_scope=\"conv1\", input_tensor=dna_sequence, num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "        l2 = max_pool_layer(name_scope=\"pool1\", input_tensor=l1, pool_size=[1, 3])\n",
    "\n",
    "        # convolutional + pooling #2\n",
    "        l3 = conv_layer(name_scope=\"conv2\", input_tensor=l2, num_kernels=30, kernel_shape=[1, 5])\n",
    "        l4 = max_pool_layer(name_scope=\"pool2\", input_tensor=l3, pool_size=[1, 4])\n",
    "\n",
    "        # convolutional + pooling #3\n",
    "        l5 = conv_layer(name_scope=\"conv3\", input_tensor=l4, num_kernels=40, kernel_shape=[1, 3])\n",
    "        l6 = max_pool_layer(name_scope=\"pool3\", input_tensor=l5, pool_size=[1, 4])\n",
    "\n",
    "        flat = flatten(l6)\n",
    "        # fully connected layers\n",
    "        l7 = tf.layers.dense(inputs=flat, units=90)\n",
    "        l8 = tf.layers.dense(inputs=l7, units=45)\n",
    "\n",
    "        logits = tf.layers.dense(inputs=l8, units=2)\n",
    "        \n",
    "#     return tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    return logits\n",
    "    \n",
    "def generator(noise_vector, batch_size, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        g_dim = 64 #Number of filters of first layer of generator \n",
    "        c_dim = 1 #dimensionality of the output\n",
    "        s = 500 #Final length of the sequence\n",
    "        \n",
    "        #We want to slowly upscale the sequence, so these values should help\n",
    "        # to make that change gradual\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "                                                                  \n",
    "        width = 4 #because we have 4 letters: ATCG\n",
    "        \n",
    "        #this is a magic number which I'm not sure what means yet\n",
    "        magic_number = 5\n",
    "        \n",
    "        h0 = tf.reshape(noise_vector, [batch_size, int(width/4), s16+1, magic_number])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        #Dimensions of h0 = batch_size x 1 x 31 x magic_number\n",
    "\n",
    "        #First DeConv Layer\n",
    "        output1_shape = [batch_size, int(width/2), s8+1, g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(value=h0, filter=W_conv1, output_shape=output1_shape, strides=[1, 2, 2, 1], padding='SAME', name=\"H_conv1\") + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, scope=\"g_bn1\")\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 1 x 62 x 256\n",
    "\n",
    "        \n",
    "        \n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, int(width/2), s4, g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, strides=[1, 1, 2, 1], padding='SAME') + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 2 x 124 x 128\n",
    "\n",
    "        \n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, width, s2, g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 4 x 248 x 64\n",
    "\n",
    "        \n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, width, s, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [1, 2, output4_shape[-1], int(H_conv3.get_shape()[-1])], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, strides=[1, 1, 2, 1], padding='VALID') + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "\n",
    "        #Dimensions of H_conv4 = batch_size x 4 x 500 x 1\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(dna_sequence, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            \n",
    "        # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "\n",
    "        # convolutional + pooling #1\n",
    "        l1 = conv_max_forward_reverse(name_scope=\"conv1\", input_tensor=dna_sequence, num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "        l2 = max_pool_layer(name_scope=\"pool1\", input_tensor=l1, pool_size=[1, 3])\n",
    "\n",
    "        # convolutional + pooling #2\n",
    "        l3 = conv_max_forward_reverse(name_scope=\"conv2\", input_tensor=l2, num_kernels=30, kernel_shape=[1, 5])\n",
    "        l4 = max_pool_layer(name_scope=\"pool2\", input_tensor=l3, pool_size=[1, 4])\n",
    "\n",
    "        # convolutional + pooling #3\n",
    "        l5 = conv_max_forward_reverse(name_scope=\"conv3\", input_tensor=l4, num_kernels=40, kernel_shape=[1, 3])\n",
    "        l6 = max_pool_layer(name_scope=\"pool3\", input_tensor=l5, pool_size=[1, 4])\n",
    "\n",
    "        flat = flatten(l6)\n",
    "        # fully connected layers\n",
    "        l7 = tf.layers.dense(inputs=flat, units=90)\n",
    "        l8 = tf.layers.dense(inputs=l7, units=45)\n",
    "\n",
    "        logits = tf.layers.dense(inputs=l8, units=2)\n",
    "        \n",
    "    return tf.argmax(logits, axis=1, name=\"softmax_tensor\")\n",
    "#     return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a sample sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 500)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "z_dimensions = 160\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "sample_sequence = generator(z_test_placeholder, 1)\n",
    "test_z = np.random.normal(-1, 1, [1,z_dimensions])\n",
    "\n",
    "train_writer = tf.summary.FileWriter('./train',\n",
    "                                      sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_sequence, feed_dict={z_test_placeholder: test_z}))\n",
    "\n",
    "my_seq = temp.squeeze()\n",
    "\n",
    "print(my_seq.shape)\n",
    "plt.imshow(my_seq, cmap='gray_r')\n",
    "plt.show()\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether the discriminator is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/dense_2/BiasAdd:0\", shape=(?, 2), dtype=float32) Tensor(\"generator/Tanh:0\", shape=(16, 4, 500, 1), dtype=float32) Tensor(\"discriminator_1/dense_2/BiasAdd:0\", shape=(16, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "tf.reset_default_graph() \n",
    "sess = tf.Session()\n",
    "\n",
    "#Placeholder for input images to the discriminator\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None, 4, 500, 1])\n",
    "#Placeholder for input noise vectors to the generator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) \n",
    "\n",
    "\n",
    "#Dx will hold discriminator prediction probabilities for the real enhancer sequences\n",
    "Dx = discriminator(x_placeholder) \n",
    "#Gz holds the generated sequences\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "#Dg will hold discriminator prediction probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "\n",
    "print(Dx, Gz, Dg)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_tensor:0\", shape=(?,), dtype=int64) Tensor(\"generator/Tanh:0\", shape=(16, 4, 500, 1), dtype=float32) Tensor(\"softmax_tensor_1:0\", shape=(16,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "tf.reset_default_graph() \n",
    "sess = tf.Session()\n",
    "\n",
    "#Placeholder for input images to the discriminator\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None, 4, 500, 1])\n",
    "#Placeholder for input noise vectors to the generator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) \n",
    "\n",
    "\n",
    "#Dx will hold discriminator prediction probabilities for the real enhancer sequences\n",
    "Dx = classifier(x_placeholder) \n",
    "#Gz holds the generated sequences\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "#Dg will hold discriminator prediction probabilities for generated images\n",
    "Dg = classifier(Gz, reuse=True)\n",
    "\n",
    "print(Dx, Gz, Dg)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: below is taken from [the tutorial here](https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial.git) (and modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble components (discriminator, generator, classifier) for triple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "tf.reset_default_graph() \n",
    "sess = tf.Session()\n",
    "\n",
    "#Placeholder for input images to the discriminator\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None, 4, 500, 1])\n",
    "#Placeholder for input noise vectors to the generator\n",
    "z_dimensions = 160\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) \n",
    "\n",
    "\n",
    "#Dx will hold discriminator prediction probabilities for the real enhancer sequences\n",
    "Dx = discriminator(x_placeholder) \n",
    "#Gz holds the generated sequences\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "#Dg will hold discriminator prediction probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator has 18 variables to train.\n",
      "Generator has 14 variables to train. \n",
      "Reusing variable scope? False\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'discriminator' in var.name]\n",
    "g_vars = [var for var in tvars if 'generator' in var.name]\n",
    "print(\"Discriminator has %d variables to train.\" % len(d_vars))\n",
    "print(\"Generator has %d variables to train. \" % len(g_vars))\n",
    "print(\"Reusing variable scope? %r\" % tf.get_variable_scope().reuse)\n",
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(?,), dtype=string)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-afe16ed8b190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m####### Specify discriminator and generator ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Dx will hold discriminator prediction probabilities for the real enhancer sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mDx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#Gz holds the generated sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-82f5225e55f0>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(dna_sequence, label_one_hot, reuse)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# convolutional + pooling #1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdna_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_pool_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pool1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-814ef478b167>\u001b[0m in \u001b[0;36mconv_layer\u001b[0;34m(name_scope, input_tensor, num_kernels, kernel_shape, stride, padding, relu, lrelu, batch_normalize, batch_normalize_training, name_suffix, batch_norm)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mweights_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_kernels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0minit_vals_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfilter_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_vals_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "z_dimensions = 160\n",
    "batch_size = 16\n",
    "iterations = 3000\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "with sess.as_default():\n",
    "    data = input_fn(\"Data/Human/positive_samples\")\n",
    "    batched_dataset = data.batch(batch_size)\n",
    "    batched_dataset_iterator = batched_dataset.make_one_shot_iterator()\n",
    "    next_element = batched_dataset_iterator.get_next()\n",
    "    print(next_element)\n",
    "\n",
    "    ####### Specify discriminator and generator ######\n",
    "    #Dx will hold discriminator prediction probabilities for the real enhancer sequences\n",
    "    Dx = discriminator(next_element) \n",
    "    #Gz holds the generated sequences\n",
    "    z_batch = np.random.normal(-1, 1, size=[1, z_dimensions])\n",
    "    Gz = generator(z_batch, batch_size, z_dimensions) \n",
    "    #Dg will hold discriminator prediction probabilities for generated images\n",
    "    Dg = discriminator(Gz, reuse=True)\n",
    "    \n",
    "    ###### Specify losses ######\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    ###### Specify optimizers ######\n",
    "    tvars = tf.trainable_variables()\n",
    "    d_vars = [var for var in tvars if 'discriminator' in var.name]\n",
    "    g_vars = [var for var in tvars if 'generator' in var.name]\n",
    "    print(\"Discriminator has %d variables to train.\" % len(d_vars))\n",
    "    print(\"Generator has %d variables to train. \" % len(g_vars))\n",
    "    print(\"Reusing variable scope? %r\" % tf.get_variable_scope().reuse)\n",
    "    adam = tf.train.AdamOptimizer()\n",
    "    trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "    trainerG = adam.minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    ###### Actually run the training\n",
    "    iterations=3000\n",
    "    for i in range(iterations):\n",
    "        z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "        real_seq_batch = batched_dataset_iterator.get_next()\n",
    "\n",
    "#         real_seq_batch = np.reshape(real_seq_batch[0], [batch_size, 4, 500, 1])\n",
    "        _,dLoss = sess.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch,x_placeholder:real_seq_batch}) #Update the discriminator\n",
    "        _,gLoss = sess.run([trainerG, g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
