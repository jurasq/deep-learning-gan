{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper definitions:\n",
    "Enhancer paper = \"Enhancer Identification from DNA sequence using Transfer and Adversarial Deep Learning\"  \n",
    "triple GAN = \"Triple Generative Adversarial Nets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 1, 20]\n",
      "[1, 2, 2, 1]\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kernel_shape=[4,9]\n",
    "input_channels = 1\n",
    "num_kernels = 20\n",
    "\n",
    "weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "print(weights_shape)\n",
    "print([1] + [2, 2] + [1])\n",
    "print(int(500/8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-0e5d861c9457>, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-0e5d861c9457>\"\u001b[0;36m, line \u001b[0;32m59\u001b[0m\n\u001b[0;31m    with tf.name_scope(name_scope)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def conv_layer(name_scope, input_tensor, num_kernels, kernel_shape,\n",
    "               stride=1, padding=\"VALID\", relu=True, \n",
    "               batch_normalize=False, batch_normalize_training=True, \n",
    "               name_suffix=None):\n",
    "    \"\"\"\n",
    "    Return a convolution layer, possibly with a ReLU at the end.\n",
    "    :param name_scope:   where the variables live\n",
    "    :param input_tensor: of shape [batch, in_height, in_width, in_channels], e.g. [15 500 4 1]\n",
    "    :param num_kernels:  number of kernels to use for this conv. layer\n",
    "    :param kernel_shape: the shape of the kernel to use, [height, width]\n",
    "    \"\"\"\n",
    "    name_suffix = name_suffix if name_suffix else \"\"\n",
    "    \n",
    "    #E.g. batch_size x 500x4x1 for the first input\n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1]\n",
    "    \n",
    "    #not really sure why I'm using the name_scope, I think it's mostly for presentation purposes\n",
    "    with tf.name_scope(name_scope):\n",
    "        \n",
    "        weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "        init_vals_weights = tf.truncated_normal(weights_shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        filter_weights = tf.Variable(init_vals_weights, name='weights'+name_suffix)\n",
    "    \n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases'+name_suffix)\n",
    "        \n",
    "        #Define a convolutional layer\n",
    "        layer = tf.nn.conv2d(input_tensor, filter_weights, strides=[1, stride, stride, 1], padding=padding) + biases\n",
    "        \n",
    "        #TODO: batch_normalization layer\n",
    "        \n",
    "        #Add (leaky) ReLU if specified\n",
    "        if relu and lrelu:\n",
    "            layer = tf.nn.leaky_relu(layer, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            layer = tf.nn.relu(layer, name=\"relu_\"+name_suffix)\n",
    "            \n",
    "        return layer\n",
    "\n",
    "    \n",
    "def max_pool_layer(name_scope, input_tensor, pool_size, strides = None, padding=\"SAME\"):\n",
    "    \"\"\"\n",
    "    Return a max pool layer.\n",
    "    \"\"\"\n",
    "    if not strides:\n",
    "        strides = [1] + pool_size + [1]\n",
    "       \n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        layer = tf.nn.max_pool(input_tensor, [1] + pool_size + [1], strides=strides, padding=padding)\n",
    "        return layer\n",
    "\n",
    "\n",
    "def dropout_layer(name_scope, input_tensor, keep_prob=0.5):\n",
    "    \"\"\"\n",
    "    Return a dropout layer.\n",
    "    \"\"\"\n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope)\n",
    "        return tf.nn.droupout(input_tensor, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_classifier(dna_sequence):\n",
    "    \"\"\"\n",
    "    Return the same classifier, with architecture the same as they used in Enhancer paper.\n",
    "    \"\"\"\n",
    "    # 20 filters, each of size batch x 4x9x1\n",
    "    # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "    l1 =  conv_layer(data, name_scope=\"layer1\", num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "    #TODO finish\n",
    "\n",
    "def discriminator(dna_sequence, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "    # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "    # convolutional + pooling #1\n",
    "    l1 = conv_layer(data, name_scope=\"conv1\", num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "    l2 = max_pool_layer(l1, name_scope=\"pool1\", pool_size=[1, 3])\n",
    "    \n",
    "    # convolutional + pooling #2\n",
    "    l3 = conv_layer(l2, name_scope=\"conv2\", num_kernels=30, kernel_shape=[1, 5])\n",
    "    l4 = max_pool_layer(l3, name_scope=\"pool2\", pool_size=[1, 4])\n",
    "    \n",
    "    # convolutional + pooling #3\n",
    "    l5 = conv_layer(l4, name_scope=\"conv3\", num_kernels=40, kernel_shape=[1, 3])\n",
    "    l6 = max_pool_layer(l5, name_scope=\"pool3\", pool_size=[1, 4])\n",
    "    \n",
    "    # fully connected\n",
    "    num_hidden = 90\n",
    "    l7 = tf.layers.dense(inputs=l6, units=num_hidden)\n",
    "    \n",
    "    num_hidden = 45\n",
    "    l8 = tf.layers.dense(inputs=l7, units=num_hidden)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=l8, units=2)\n",
    "    return tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    \n",
    "def generator(noise_vector, batch_size, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        g_dim = 64 #Number of filters of first layer of generator \n",
    "        c_dim = 1 #dimensionality of the output\n",
    "        s = 500 #Final length of the sequence\n",
    "        \n",
    "        #We want to slowly upscale the sequence, so these values should help\n",
    "        # to make that change gradual\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "                                                                  \n",
    "        width = 4 #because we have 4 letters: ATCG\n",
    "        \n",
    "        #this is a magic number which I'm not sure what means yet\n",
    "        magic_number = 5\n",
    "        \n",
    "        h0 = tf.reshape(noise_vector, [batch_size, s16, width/4, magic_number])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        #Dimensions of h0 = batch_size x 31 x 1 x magic_number\n",
    "\n",
    "        #First DeConv Layer\n",
    "        output1_shape = [batch_size, s8, width/2, g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(value=h0, filter=W_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME', name=\"H_conv1\") + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn1\")\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 62 x 1 x 256\n",
    "        print(\"H_conv1:\")\n",
    "        print(H_conv1.shape)\n",
    "        \n",
    "        \n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, s4-1, width/2, g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                         strides=[1, 2, 1, 1], padding='SAME') + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 124 x 2 x 128\n",
    "        print(\"H_conv2:\")\n",
    "        print(H_conv2.shape)\n",
    "        \n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, s2-2, width, g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 248 x 4 x 64\n",
    "        print(\"H_conv3:\")\n",
    "        print(H_conv3.shape)\n",
    "        \n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, s, width*2, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                         strides=[1, 2, 1, 1], padding='VALID') + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "        print(\"H_conv4:\")\n",
    "        print(H_conv4.shape)\n",
    "        #Dimensions of H_conv4 = batch_size x 500 x 4 x 1\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a sample sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_conv1:\n",
      "(1, 62, 2, 256)\n",
      "H_conv2:\n",
      "(1, 124, 2, 128)\n",
      "H_conv3:\n",
      "(1, 248, 4, 64)\n",
      "H_conv4:\n",
      "(1, 500, 8, 1)\n",
      "READY TO RUN SESS\n",
      "(500, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "z_dimensions = 155\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "sample_sequence = generator(z_test_placeholder, 1)\n",
    "test_z = np.random.normal(-1, 1, [1,z_dimensions])\n",
    "\n",
    "train_writer = tf.summary.FileWriter('./train',\n",
    "                                      sess.graph)\n",
    "print(\"READY TO RUN SESS\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_sequence, feed_dict={z_test_placeholder: test_z}))\n",
    "\n",
    "my_seq = temp.squeeze()\n",
    "\n",
    "print(my_seq.shape)\n",
    "plt.imshow(my_seq, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: below is taken from [the tutorial here](https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial.git) (and modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble components (discriminator, generator, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: adjust to our needs\n",
    "sess = tf.Session()\n",
    "z_dimensions = 5120\n",
    "batch_size = 16\n",
    "tf.reset_default_graph() #Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,500,4,1]) #Placeholder for input sequences to the discriminator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) #Placeholder for input noise vectors to the generator\n",
    "label_placeholder = tf.placeholder(\"int\", shape= [None, 1, 2, 1]) #Placeholder for one-hot-encoded label\n",
    "\n",
    "Dx = discriminator(x_placeholder, label_placeholder) #Dx will hold discriminator prediction probabilities for the real input sequences\n",
    "Gz = generator(z_placeholder,label_placeholder, batch_size, z_dimensions) #Gz holds the generated sequences\n",
    "Dg = discriminator(Gz, label_placeholder, reuse=True) #Dg will hold discriminator prediction probabilities for generated sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: specify the right losses etc\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: adjust to our needs\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print(tf.get_variable_scope().reuse)\n",
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make it compatible with our dataset\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 3000\n",
    "for i in range(iterations):\n",
    "    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)\n",
    "    real_image_batch = np.reshape(real_image_batch[0],[batch_size,28,28,1])\n",
    "    _,dLoss = sess.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch,x_placeholder:real_image_batch}) #Update the discriminator\n",
    "    _,gLoss = sess.run([trainerG,g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
