{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nroy0\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper definitions:\n",
    "Enhancer paper = \"Enhancer Identification from DNA sequence using Transfer and Adversarial Deep Learning\"  \n",
    "triple GAN = \"Triple Generative Adversarial Nets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 1, 20]\n",
      "[1, 2, 2, 1]\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kernel_shape=[4,9]\n",
    "input_channels = 1\n",
    "num_kernels = 20\n",
    "\n",
    "weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "print(weights_shape)\n",
    "print([1] + [2, 2] + [1])\n",
    "print(int(500/8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(name_scope, input_tensor, num_kernels, kernel_shape,\n",
    "               stride=1, padding=\"VALID\", relu=True, \n",
    "               batch_normalize=False, batch_normalize_training=True, \n",
    "               name_suffix=None):\n",
    "    \"\"\"\n",
    "    Return a convolution layer, possibly with a ReLU at the end.\n",
    "    :param name_scope:   where the variables live\n",
    "    :param input_tensor: of shape [batch, in_height, in_width, in_channels], e.g. [15 500 4 1]\n",
    "    :param num_kernels:  number of kernels to use for this conv. layer\n",
    "    :param kernel_shape: the shape of the kernel to use, [height, width]\n",
    "    \"\"\"\n",
    "    name_suffix = name_suffix if name_suffix else \"\"\n",
    "    \n",
    "    #E.g. batch_size x 500x4x1 for the first input\n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1]\n",
    "    \n",
    "    #not really sure why I'm using the name_scope, I think it's mostly for presentation purposes\n",
    "    with tf.name_scope(name_scope):\n",
    "        \n",
    "        weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "        init_vals_weights = tf.truncated_normal(weights_shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        filter_weights = tf.Variable(init_vals_weights, name='weights'+name_suffix)\n",
    "    \n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases'+name_suffix)\n",
    "        \n",
    "        #Define a convolutional layer\n",
    "        layer = tf.nn.conv2d(input_tensor, filter_weights, strides=[1, stride, stride, 1], padding=padding) + biases\n",
    "        \n",
    "        #TODO: batch_normalization layer\n",
    "        \n",
    "        #Add (leaky) ReLU if specified\n",
    "        if relu and lrelu:\n",
    "            layer = tf.nn.leaky_relu(layer, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            layer = tf.nn.relu(layer, name=\"relu_\"+name_suffix)\n",
    "            \n",
    "        return layer\n",
    "\n",
    "def conv_max_forward_reverse(name_scope, input_tensor, num_kernels, kernel_size, project,\n",
    "                             PWM_file=None, weights_are_constant=False, stride=1,\n",
    "                             padding='VALID', relu=True, init_according_to_given_filters=False,\n",
    "                             init_model_ids=None):\n",
    "    \"\"\"\n",
    "    Returns a convolution layer\n",
    "    \"\"\"\n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1] # number of input channels\n",
    "    with tf.name_scope(name_scope):\n",
    "#         if PWM_file:\n",
    "#             PWM = read_PWM_from_file(PWM_file)\n",
    "#             motif_length = len(PWM)\n",
    "#             if weights_are_constant:\n",
    "#                 # in this case - use Constant weights! not Variable, so they cannot be changed at all\n",
    "#                 const_filter = tf.constant(PWM, tf.float32)\n",
    "#                 weights = tf.reshape(const_filter, [BASIS_NUMBER, motif_length, 1, 1], name='weights')\n",
    "\n",
    "#             else:\n",
    "#                 const_filter = tf.constant(PWM, tf.float32)\n",
    "#                 weights = tf.Variable(tf.reshape(const_filter, [BASIS_NUMBER, motif_length, 1, 1]), name='weights')\n",
    "#         elif init_according_to_given_filters:\n",
    "#             all_filters_all_ks = []\n",
    "#             num_ks = len([2, 3, 4])\n",
    "#             num_kernels_one_k = int(project.CNN_structure.conv_num_kernels[0] / (num_ks + 1))\n",
    "#             for k in range(num_ks+1):\n",
    "#                 if k == num_ks:  # random initialization\n",
    "#                     all_filters_one_k = get_random_values(1, project, num_kernels_one_k)\n",
    "#                 else:\n",
    "#                     model_id = init_model_ids[k]\n",
    "#                     all_filters_one_k = read_all_filters_in_layer(1, model_id, project, num_kernels_one_k)\n",
    "#                 all_filters_all_ks.extend(all_filters_one_k)\n",
    "#             array_all_filters_all_ks = np.array(all_filters_all_ks)\n",
    "#             num_filters = array_all_filters_all_ks.shape[0]  # 120\n",
    "#             # since it is the first layer:\n",
    "#             first_filter_dimension = kernel_size[0]\n",
    "#             second_filter_dimension = kernel_size[1]\n",
    "#             const_filter = tf.constant(array_all_filters_all_ks, tf.float32)\n",
    "#             weights = tf.Variable(tf.reshape(const_filter,\n",
    "#                                              [first_filter_dimension, second_filter_dimension, 1, num_filters]),\n",
    "#                                   name='weights')\n",
    "#         else:\n",
    "        shape = kernel_size + [input_channels, num_kernels]\n",
    "        initer = tf.truncated_normal(shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        weights = tf.Variable(initer, name='weights')\n",
    "        num_kernels = weights.get_shape()[3]\n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases')\n",
    "\n",
    "        # If one component of shape is the special value -1, the size of that dimension is computed\n",
    "        #  so that the total size remains constant.\n",
    "        # In our case: -1 is inferred to be input_channels * out_channels:\n",
    "        new_weights_shape = [-1] + kernel_size + [1]\n",
    "        w_image = tf.reshape(weights, new_weights_shape)\n",
    "        tf.summary.image(name_scope + \"_weights_im\", w_image, weights.get_shape()[3])\n",
    "        forward_conv = tf.nn.conv2d(input_tensor, weights, strides=[1, stride, stride, 1], padding=padding,\n",
    "                               name=\"forward_conv\") + biases\n",
    "        # for reverse complement: reverse in dimension 0 and 1:\n",
    "        rev_comp_weights = tf.reverse(weights, [0, 1], name=\"reverse_weights\")\n",
    "        reverse_conv = tf.nn.conv2d(input_tensor, rev_comp_weights,\n",
    "                                    strides=[1, stride, stride, 1], padding=padding,\n",
    "                                    name=\"reverse_conv\") + biases\n",
    "        # takes the maximum between the forward weights and the rev.-comp.-weights:\n",
    "        max_conv = tf.maximum(forward_conv, reverse_conv, name=\"conv1\")\n",
    "        if relu and lrelu:\n",
    "            return tf.nn.leaky_relu(max_conv, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            return tf.nn.relu(max_conv, name=\"relu_\"+name_suffix)\n",
    "        else:\n",
    "            return max_conv\n",
    "        \n",
    "def max_pool_layer(name_scope, input_tensor, pool_size, strides = None, padding=\"SAME\"):\n",
    "    \"\"\"\n",
    "    Return a max pool layer.\n",
    "    \"\"\"\n",
    "    if not strides:\n",
    "        strides = [1] + pool_size + [1]\n",
    "       \n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        layer = tf.nn.max_pool(input_tensor, [1] + pool_size + [1], strides=strides, padding=padding)\n",
    "        return layer\n",
    "\n",
    "\n",
    "def dropout_layer(name_scope, input_tensor, keep_prob=0.5):\n",
    "    \"\"\"\n",
    "    Return a dropout layer.\n",
    "    \"\"\"\n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        return tf.nn.droupout(input_tensor, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_classifier(dna_sequence):\n",
    "    \"\"\"\n",
    "    Return the same classifier, with architecture the same as they used in Enhancer paper.\n",
    "    \"\"\"\n",
    "    # 20 filters, each of size batch x 4x9x1\n",
    "    # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "    l1 =  conv_layer(data, name_scope=\"layer1\", num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "    #TODO finish\n",
    "\n",
    "def discriminator(dna_sequence, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "    # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "    # convolutional + pooling #1\n",
    "    l1 = conv_layer(data, name_scope=\"conv1\", num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "    l2 = max_pool_layer(l1, name_scope=\"pool1\", pool_size=[1, 3])\n",
    "    \n",
    "    # convolutional + pooling #2\n",
    "    l3 = conv_layer(l2, name_scope=\"conv2\", num_kernels=30, kernel_shape=[1, 5])\n",
    "    l4 = max_pool_layer(l3, name_scope=\"pool2\", pool_size=[1, 4])\n",
    "    \n",
    "    # convolutional + pooling #3\n",
    "    l5 = conv_layer(l4, name_scope=\"conv3\", num_kernels=40, kernel_shape=[1, 3])\n",
    "    l6 = max_pool_layer(l5, name_scope=\"pool3\", pool_size=[1, 4])\n",
    "    \n",
    "    # fully connected\n",
    "    num_hidden = 90\n",
    "    l7 = tf.layers.dense(inputs=l6, units=num_hidden)\n",
    "    \n",
    "    num_hidden = 45\n",
    "    l8 = tf.layers.dense(inputs=l7, units=num_hidden)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=l8, units=2)\n",
    "    return tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    \n",
    "def generator(noise_vector, batch_size, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        g_dim = 64 #Number of filters of first layer of generator \n",
    "        c_dim = 1 #dimensionality of the output\n",
    "        s = 500 #Final length of the sequence\n",
    "        \n",
    "        #We want to slowly upscale the sequence, so these values should help\n",
    "        # to make that change gradual\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "                                                                  \n",
    "        width = 4 #because we have 4 letters: ATCG\n",
    "        \n",
    "        #this is a magic number which I'm not sure what means yet\n",
    "        magic_number = 5\n",
    "        \n",
    "        h0 = tf.reshape(noise_vector, [batch_size, s16+1, width/4, magic_number])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        #Dimensions of h0 = batch_size x 31 x 1 x magic_number\n",
    "\n",
    "        #First DeConv Layer\n",
    "        output1_shape = [batch_size, s8+1, width/2, g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(value=h0, filter=W_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME', name=\"H_conv1\") + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn1\")\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 62 x 1 x 256\n",
    "        print(\"H_conv1:\")\n",
    "        print(H_conv1.shape)\n",
    "        \n",
    "        \n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, s4, width/2, g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                         strides=[1, 2, 1, 1], padding='SAME') + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 124 x 2 x 128\n",
    "        print(\"H_conv2:\")\n",
    "        print(H_conv2.shape)\n",
    "        \n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, s2, width, g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 248 x 4 x 64\n",
    "        print(\"H_conv3:\")\n",
    "        print(H_conv3.shape)\n",
    "        \n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, s, width, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [2, 1, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                         strides=[1, 2, 1, 1], padding='VALID') + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "        print(\"H_conv4:\")\n",
    "        print(H_conv4.shape)\n",
    "        #Dimensions of H_conv4 = batch_size x 500 x 4 x 1\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a sample sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_conv1:\n",
      "(1, 63, 2, 256)\n",
      "H_conv2:\n",
      "(1, 125, 2, 128)\n",
      "H_conv3:\n",
      "(1, 250, 2, 64)\n",
      "H_conv4:\n",
      "(1, 500, 4, 1)\n",
      "READY TO RUN SESS\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Conv2DCustomBackpropInput: Size of out_backprop doesn't match computed: actual = 2, computed = 1spatial_dim: 2 input: 2 filter: 5 output: 2 stride: 2 dilation: 1\n\t [[Node: generator/conv2d_transpose_1 = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](generator/conv2d_transpose_1/output_shape, generator/g_wconv3/read, generator/Relu_2)]]\n\nCaused by op u'generator/conv2d_transpose_1', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-134-c946cf27212e>\", line 6, in <module>\n    sample_sequence = generator(z_test_placeholder, 1)\n  File \"<ipython-input-133-70515463b8b3>\", line 93, in generator\n    strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1254, in conv2d_transpose\n    name=name)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1228, in conv2d_backprop_input\n    dilations=dilations, name=name)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Conv2DCustomBackpropInput: Size of out_backprop doesn't match computed: actual = 2, computed = 1spatial_dim: 2 input: 2 filter: 5 output: 2 stride: 2 dilation: 1\n\t [[Node: generator/conv2d_transpose_1 = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](generator/conv2d_transpose_1/output_shape, generator/g_wconv3/read, generator/Relu_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-c946cf27212e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"READY TO RUN SESS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_test_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmy_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Conv2DCustomBackpropInput: Size of out_backprop doesn't match computed: actual = 2, computed = 1spatial_dim: 2 input: 2 filter: 5 output: 2 stride: 2 dilation: 1\n\t [[Node: generator/conv2d_transpose_1 = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](generator/conv2d_transpose_1/output_shape, generator/g_wconv3/read, generator/Relu_2)]]\n\nCaused by op u'generator/conv2d_transpose_1', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-134-c946cf27212e>\", line 6, in <module>\n    sample_sequence = generator(z_test_placeholder, 1)\n  File \"<ipython-input-133-70515463b8b3>\", line 93, in generator\n    strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1254, in conv2d_transpose\n    name=name)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1228, in conv2d_backprop_input\n    dilations=dilations, name=name)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Conv2DCustomBackpropInput: Size of out_backprop doesn't match computed: actual = 2, computed = 1spatial_dim: 2 input: 2 filter: 5 output: 2 stride: 2 dilation: 1\n\t [[Node: generator/conv2d_transpose_1 = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](generator/conv2d_transpose_1/output_shape, generator/g_wconv3/read, generator/Relu_2)]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "z_dimensions = 160\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "sample_sequence = generator(z_test_placeholder, 1)\n",
    "test_z = np.random.normal(-1, 1, [1,z_dimensions])\n",
    "\n",
    "train_writer = tf.summary.FileWriter('./train',\n",
    "                                      sess.graph)\n",
    "print(\"READY TO RUN SESS\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_sequence, feed_dict={z_test_placeholder: test_z}))\n",
    "\n",
    "my_seq = temp.squeeze()\n",
    "print(my_seq)\n",
    "print(my_seq.shape)\n",
    "plt.imshow(my_seq, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: below is taken from [the tutorial here](https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial.git) (and modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble components (discriminator, generator, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: adjust to our needs\n",
    "sess = tf.Session()\n",
    "z_dimensions = 5120\n",
    "batch_size = 16\n",
    "tf.reset_default_graph() #Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,500,4,1]) #Placeholder for input sequences to the discriminator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) #Placeholder for input noise vectors to the generator\n",
    "label_placeholder = tf.placeholder(\"int\", shape= [None, 1, 2, 1]) #Placeholder for one-hot-encoded label\n",
    "\n",
    "Dx = discriminator(x_placeholder, label_placeholder) #Dx will hold discriminator prediction probabilities for the real input sequences\n",
    "Gz = generator(z_placeholder,label_placeholder, batch_size, z_dimensions) #Gz holds the generated sequences\n",
    "Dg = discriminator(Gz, label_placeholder, reuse=True) #Dg will hold discriminator prediction probabilities for generated sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: specify the right losses etc\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: adjust to our needs\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print(tf.get_variable_scope().reuse)\n",
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make it compatible with our dataset\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 3000\n",
    "for i in range(iterations):\n",
    "    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)\n",
    "    real_image_batch = np.reshape(real_image_batch[0],[batch_size,28,28,1])\n",
    "    _,dLoss = sess.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch,x_placeholder:real_image_batch}) #Update the discriminator\n",
    "    _,gLoss = sess.run([trainerG,g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
