{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper definitions:\n",
    "Enhancer paper = \"Enhancer Identification from DNA sequence using Transfer and Adversarial Deep Learning\"  \n",
    "triple GAN = \"Triple Generative Adversarial Nets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_fn(sample):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        sample: (string) String of DNA data of length n, example: ACTGTA...\n",
    "    Outputs:\n",
    "        A numpy array of size n x 4 where A in the DNA sequence has been replace with [1 0 0 0], C with [0 1 0 0],\n",
    "        G with [0 0 1 0] and T with [0 0 0 1].\n",
    "    \"\"\"\n",
    "    mapping = tf.constant([\"A\", \"C\", \"G\", \"T\"])\n",
    "    embeddings = tf.constant([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "        \n",
    "    sample_split = tf.string_split([sample], '')\n",
    "    lookup_table = tf.contrib.lookup.index_table_from_tensor(mapping = mapping, num_oov_buckets = 0)\n",
    "#     lookup_table.init.run()\n",
    "    sample_indices = lookup_table.lookup(sample_split.values)\n",
    "    encoded = tf.nn.embedding_lookup(embeddings, sample_indices)\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "    \n",
    "def input_fn(data_file_names):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        data_file_names: (string/string array) List of files to be loaded. * can be used as a wildcard in file names.\n",
    "    Outputs:\n",
    "        Tensor flow dataset containing the data matrices from data_file_names\n",
    "    \"\"\"\n",
    "    files = tf.data.Dataset.list_files(data_file_names)\n",
    "    dataset = files.interleave(lambda x: tf.data.TextLineDataset(x).map(data_process_fn), cycle_length = 1)\n",
    "#     dataset = files.interleave(lambda x: tf.data.TextLineDataset(x), cycle_length = 1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of data loading - human positive samples\n",
    "\n",
    "with  tf.Session() as sess:\n",
    "    \n",
    "    input_data_example = input_fn(\"Data/Human/positive_samples\")\n",
    "    iter = input_data_example.make_one_shot_iterator()\n",
    "    val = iter.get_next()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_shape=[4,9]\n",
    "input_channels = 1\n",
    "num_kernels = 20\n",
    "\n",
    "weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "print(weights_shape)\n",
    "print([1] + [2, 2] + [1])\n",
    "print(int(500/8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(name_scope, input_tensor, num_kernels, kernel_shape,\n",
    "               stride=1, padding=\"VALID\", relu=True, lrelu=False,\n",
    "               batch_normalize=False, batch_normalize_training=True, \n",
    "               name_suffix=None, batch_norm=False):\n",
    "    \"\"\"\n",
    "    Return a convolution layer, possibly with a ReLU at the end.\n",
    "    :param name_scope:   where the variables live\n",
    "    :param input_tensor: of shape [batch, in_height, in_width, in_channels], e.g. [15 500 4 1]\n",
    "    :param num_kernels:  number of kernels to use for this conv. layer\n",
    "    :param kernel_shape: the shape of the kernel to use, [height, width]\n",
    "    \"\"\"\n",
    "    name_suffix = name_suffix if name_suffix else \"\"\n",
    "    \n",
    "    #E.g. batch_size x 500x4x1 for the first input\n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1]\n",
    "    \n",
    "    #not really sure why I'm using the name_scope, I think it's mostly for presentation purposes\n",
    "    with tf.name_scope(name_scope):\n",
    "        \n",
    "        weights_shape = kernel_shape + [input_channels, num_kernels]\n",
    "        init_vals_weights = tf.truncated_normal(weights_shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        filter_weights = tf.Variable(init_vals_weights, name='weights'+name_suffix)\n",
    "    \n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases'+name_suffix)\n",
    "        \n",
    "        #Define a convolutional layer\n",
    "        layer = tf.nn.conv2d(input_tensor, filter_weights, strides=[1, stride, stride, 1], padding=padding) + biases\n",
    "        \n",
    "        #Add batch normalisation if specified\n",
    "        #TODO: is_training always True?\n",
    "        if batch_norm:\n",
    "            layer = tf.contrib.layers.batch_norm(inputs = layer, center=True, scale=True, is_training=True)\n",
    "            \n",
    "        #Add (leaky) ReLU if specified\n",
    "        if relu and lrelu:\n",
    "            layer = tf.nn.leaky_relu(layer, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            layer = tf.nn.relu(layer, name=\"relu_\"+name_suffix)\n",
    "            \n",
    "        return layer\n",
    "\n",
    "def conv_max_forward_reverse(name_scope, input_tensor, num_kernels, kernel_size, project,\n",
    "                             stride=1, padding='VALID', relu=True, lrelu=False):\n",
    "    \"\"\"\n",
    "    Returns a convolution layer\n",
    "    \"\"\"\n",
    "    input_shape = input_tensor.get_shape().as_list()\n",
    "    input_channels = input_shape[-1] # number of input channels\n",
    "    with tf.name_scope(name_scope):\n",
    "        shape = kernel_size + [input_channels, num_kernels]\n",
    "        initer = tf.truncated_normal(shape, stddev=math.sqrt(2 / float(input_channels)))\n",
    "        weights = tf.Variable(initer, name='weights')\n",
    "        num_kernels = weights.get_shape()[3]\n",
    "        biases = tf.Variable(tf.zeros([num_kernels]), name='biases')\n",
    "\n",
    "        # If one component of shape is the special value -1, the size of that dimension is computed\n",
    "        #  so that the total size remains constant.\n",
    "        # In our case: -1 is inferred to be input_channels * out_channels:\n",
    "        new_weights_shape = [-1] + kernel_size + [1]\n",
    "        w_image = tf.reshape(weights, new_weights_shape)\n",
    "        tf.summary.image(name_scope + \"_weights_im\", w_image, weights.get_shape()[3])\n",
    "        forward_conv = tf.nn.conv2d(input_tensor, weights, strides=[1, stride, stride, 1], padding=padding,\n",
    "                               name=\"forward_conv\") + biases\n",
    "        # for reverse complement: reverse in dimension 0 and 1:\n",
    "        rev_comp_weights = tf.reverse(weights, [0, 1], name=\"reverse_weights\")\n",
    "        reverse_conv = tf.nn.conv2d(input_tensor, rev_comp_weights,\n",
    "                                    strides=[1, stride, stride, 1], padding=padding,\n",
    "                                    name=\"reverse_conv\") + biases\n",
    "        # takes the maximum between the forward weights and the rev.-comp.-weights:\n",
    "        max_conv = tf.maximum(forward_conv, reverse_conv, name=\"conv1\")\n",
    "        if relu and lrelu:\n",
    "            return tf.nn.leaky_relu(max_conv, name=\"lrelu_\"+name_suffix)\n",
    "        elif relu:\n",
    "            return tf.nn.relu(max_conv, name=\"relu_\"+name_suffix)\n",
    "        else:\n",
    "            return max_conv\n",
    "        \n",
    "def max_pool_layer(name_scope, input_tensor, pool_size, strides = None, padding=\"SAME\"):\n",
    "    \"\"\"\n",
    "    Return a max pool layer.\n",
    "    \"\"\"\n",
    "    if not strides:\n",
    "        strides = [1] + pool_size + [1]\n",
    "       \n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        layer = tf.nn.max_pool(input_tensor, [1] + pool_size + [1], strides=strides, padding=padding)\n",
    "        return layer\n",
    "\n",
    "\n",
    "def dropout_layer(name_scope, input_tensor, keep_prob=0.5):\n",
    "    \"\"\"\n",
    "    Return a dropout layer.\n",
    "    \"\"\"\n",
    "    #TODO: is name_scope really needed?\n",
    "    with tf.name_scope(name_scope):\n",
    "        return tf.nn.droupout(input_tensor, keep_prob)\n",
    "    \n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    Returns a flat (one-dimensional) version of the input\n",
    "    \"\"\"\n",
    "    x_shape = x.get_shape().as_list()\n",
    "    return tf.reshape(x, [-1, np.product(x_shape[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(dna_sequence):\n",
    "    \"\"\"\n",
    "    Return the same classifier, with architecture the same as they used in Enhancer paper.\n",
    "    \"\"\"\n",
    "    # 20 filters, each of size batch x 9x4x1\n",
    "    # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "    l1 =  conv_layer(data, name_scope=\"layer1\", num_kernels=20, kernel_shape=[4, 9], relu=True)\n",
    "    #TODO finish\n",
    "\n",
    "def discriminator(dna_sequence, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            \n",
    "        # TODO: make a reverse filter conv layer like in the Enhancer paper \n",
    "\n",
    "        # convolutional + pooling #1\n",
    "        l1 = conv_layer(name_scope=\"conv1\", input_tensor=dna_sequence, num_kernels=20, \n",
    "                        kernel_shape=[4, 9], relu=True)\n",
    "        l2 = max_pool_layer(name_scope=\"pool1\", input_tensor=l1, pool_size=[1, 3])\n",
    "\n",
    "        # convolutional + pooling #2\n",
    "        l3 = conv_layer(name_scope=\"conv2\", input_tensor=l2, num_kernels=30, kernel_shape=[1, 5])\n",
    "        l4 = max_pool_layer(name_scope=\"pool2\", input_tensor=l3, pool_size=[1, 4])\n",
    "\n",
    "        # convolutional + pooling #3\n",
    "        l5 = conv_layer(name_scope=\"conv3\", input_tensor=l4, num_kernels=40, kernel_shape=[1, 3])\n",
    "        l6 = max_pool_layer(name_scope=\"pool3\", input_tensor=l5, pool_size=[1, 4])\n",
    "\n",
    "        flat = flatten(l6)\n",
    "        # fully connected layers\n",
    "        l7 = tf.layers.dense(inputs=flat, units=90)\n",
    "        l8 = tf.layers.dense(inputs=l7, units=45)\n",
    "\n",
    "        logits = tf.layers.dense(inputs=l8, units=2)\n",
    "        \n",
    "#     return tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    return logits\n",
    "    \n",
    "def generator(noise_vector, batch_size, label_one_hot=None, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        g_dim = 64 #Number of filters of first layer of generator \n",
    "        c_dim = 1 #dimensionality of the output\n",
    "        s = 500 #Final length of the sequence\n",
    "        \n",
    "        #We want to slowly upscale the sequence, so these values should help\n",
    "        # to make that change gradual\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "                                                                  \n",
    "        width = 4 #because we have 4 letters: ATCG\n",
    "        \n",
    "        #this is a magic number which I'm not sure what means yet\n",
    "        magic_number = 5\n",
    "        \n",
    "        h0 = tf.reshape(noise_vector, [batch_size, width/4, s16+1, magic_number])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        #Dimensions of h0 = batch_size x 1 x 31 x magic_number\n",
    "\n",
    "        #First DeConv Layer\n",
    "        output1_shape = [batch_size, width/2, s8+1, g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(value=h0, filter=W_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME', name=\"H_conv1\") + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn1\")\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 1 x 62 x 256\n",
    "\n",
    "        \n",
    "        \n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, width/2, s4, g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                         strides=[1, 1, 2, 1], padding='SAME') + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 2 x 124 x 128\n",
    "\n",
    "        \n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, width, s2, g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, \n",
    "                                               scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 4 x 248 x 64\n",
    "\n",
    "        \n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, width, s, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [1, 2, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                         strides=[1, 1, 2, 1], padding='VALID') + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "\n",
    "        #Dimensions of H_conv4 = batch_size x 4 x 500 x 1\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a sample sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 500)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "z_dimensions = 160\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "sample_sequence = generator(z_test_placeholder, 1)\n",
    "test_z = np.random.normal(-1, 1, [1,z_dimensions])\n",
    "\n",
    "train_writer = tf.summary.FileWriter('./train',\n",
    "                                      sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_sequence, feed_dict={z_test_placeholder: test_z}))\n",
    "\n",
    "my_seq = temp.squeeze()\n",
    "\n",
    "print(my_seq.shape)\n",
    "plt.imshow(my_seq, cmap='gray_r')\n",
    "plt.show()\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether the discriminator is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/dense_2/BiasAdd:0\", shape=(?, 2), dtype=float32) Tensor(\"generator/Tanh:0\", shape=(16, 4, 500, 1), dtype=float32) Tensor(\"discriminator_1/dense_2/BiasAdd:0\", shape=(16, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "tf.reset_default_graph() \n",
    "sess = tf.Session()\n",
    "\n",
    "#Placeholder for input images to the discriminator\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None, 4, 500, 1])\n",
    "#Placeholder for input noise vectors to the generator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) \n",
    "\n",
    "\n",
    "#Dx will hold discriminator prediction probabilities for the real enhancer sequences\n",
    "Dx = discriminator(x_placeholder) \n",
    "#Gz holds the generated sequences\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "#Dg will hold discriminator prediction probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "\n",
    "print(Dx, Gz, Dg)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: below is taken from [the tutorial here](https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial.git) (and modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble components (discriminator, generator, classifier) for triple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "tf.reset_default_graph() \n",
    "sess = tf.Session()\n",
    "\n",
    "#Placeholder for input images to the discriminator\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None, 4, 500, 1])\n",
    "#Placeholder for input noise vectors to the generator\n",
    "z_dimensions = 160\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) \n",
    "\n",
    "\n",
    "#Dx will hold discriminator prediction probabilities for the real enhancer sequences\n",
    "Dx = discriminator(x_placeholder) \n",
    "#Gz holds the generated sequences\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "#Dg will hold discriminator prediction probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator has 18 variables to train.\n",
      "Generator has 14 variables to train. \n",
      "Reusing variable scope? False\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'discriminator' in var.name]\n",
    "g_vars = [var for var in tvars if 'generator' in var.name]\n",
    "print(\"Discriminator has %d variables to train.\" % len(d_vars))\n",
    "print(\"Generator has %d variables to train. \" % len(g_vars))\n",
    "print(\"Reusing variable scope? %r\" % tf.get_variable_scope().reuse)\n",
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Table already initialized.\n\t [[Node: string_to_index/hash_table/table_init = InitializeTableV2[Tkey=DT_STRING, Tval=DT_INT64](string_to_index/hash_table, Const, string_to_index/ToInt64)]]\n\t [[Node: IteratorGetNext_18 = IteratorGetNext[output_shapes=[[?,?,4]], output_types=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_13)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b493697da567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mreal_seq_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_dataset_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mreal_seq_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#     print(real_seq_batch.get_shape())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     real_seq_batch = np.reshape(real_seq_batch, [batch_size, 4, 500, 1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \"\"\"\n\u001b[0;32m--> 710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5178\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5180\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/dev/.virtualenvs/project-5LwxXb3z/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Table already initialized.\n\t [[Node: string_to_index/hash_table/table_init = InitializeTableV2[Tkey=DT_STRING, Tval=DT_INT64](string_to_index/hash_table, Const, string_to_index/ToInt64)]]\n\t [[Node: IteratorGetNext_18 = IteratorGetNext[output_shapes=[[?,?,4]], output_types=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_13)]]"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 3000\n",
    "with sess.as_default():\n",
    "    data = input_fn(\"Data/Human/positive_samples\")\n",
    "    batched_dataset = data.batch(batch_size)\n",
    "    batched_dataset_iterator = batched_dataset.make_one_shot_iterator()\n",
    "\n",
    "iterations=3000\n",
    "for i in range(iterations):\n",
    "    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "    real_seq_batch = batched_dataset_iterator.get_next()\n",
    "    real_seq_batch.eval(session=sess)\n",
    "#     print(real_seq_batch.get_shape())\n",
    "#     real_seq_batch = np.reshape(real_seq_batch, [batch_size, 4, 500, 1])\n",
    "    _,dLoss = sess.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch,x_placeholder:real_seq_batch}) #Update the discriminator\n",
    "    _,gLoss = sess.run([trainerG, g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
